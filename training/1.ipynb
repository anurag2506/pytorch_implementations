{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff121ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "from torch.optim import SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7fffc56",
   "metadata": {},
   "source": [
    "### Important Bug fixes:\n",
    "1. Mkae sure model and the tensors fed are in the same device: move inputs, targets, and models to the same device\n",
    "2. For linear layers, the nn.Linear(param1, param2) assumes: param1 -> input features for the model and for a supervised task like image classification the features are all the RGB pixels for all the 256x256 = 65536 pixels. The features => 196608 feautures and based on the structure of your MLP, we can downsize the features into smaller and smaller dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7acacead",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import SGD\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "\n",
    "def training():\n",
    "    # Setting seed for reproducability:\n",
    "    torch.manual_seed(23)\n",
    "    inp = torch.rand(size = (20,5),device=device)\n",
    "    tar = torch.rand(size = (20,1),device=device)\n",
    "    epochs = 10\n",
    "    model = nn.Linear(5,1).to(device=device)\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=1e-1, momentum=0.9)\n",
    "    loss = nn.MSELoss()\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        optimizer.zero_grad()\n",
    "        output = model(inp) # Forward pass\n",
    "        avg_loss = loss(output,tar) # Loss\n",
    "        avg_loss.backward() # Backward\n",
    "        optimizer.step() # Step: updates weights\n",
    "        \n",
    "        print(f\"{epoch+1}/{epochs} : {avg_loss.item()}\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "487d4ca1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Loss fo epoch-1/10 : 0.8533935546875\n",
      "2. Loss fo epoch-2/10 : 0.3009968400001526\n",
      "3. Loss fo epoch-3/10 : 0.08727125078439713\n",
      "4. Loss fo epoch-4/10 : 0.41451579332351685\n",
      "5. Loss fo epoch-5/10 : 0.6144632697105408\n",
      "6. Loss fo epoch-6/10 : 0.3466690480709076\n",
      "7. Loss fo epoch-7/10 : 0.06256309151649475\n",
      "8. Loss fo epoch-8/10 : 0.15740029513835907\n",
      "9. Loss fo epoch-9/10 : 0.37010303139686584\n",
      "10. Loss fo epoch-10/10 : 0.31146764755249023\n"
     ]
    }
   ],
   "source": [
    "training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "927da7f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n1. Use a dataloader with mini-batch of size=5\\n2. model updates weights 4 times per epoch\\n'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Improvements to be made:\n",
    "'''\n",
    "1. Use a dataloader with mini-batch of size=5\n",
    "2. model updates weights 4 times per epoch\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f4e339d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import SGD\n",
    "from torch.utils.data import Dataset,DataLoader, TensorDataset\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "def batched_training():\n",
    "    torch.manual_seed(23)\n",
    "    inp = torch.rand((20,5)).to(device)\n",
    "    tar = torch.rand((20,1)).to(device)\n",
    "    model = nn.Linear(5,1).to(device)\n",
    "    \n",
    "    data = TensorDataset(inp,tar)\n",
    "    batched_data = DataLoader(data,batch_size=5,shuffle=True) # contains batched (data,labels) \n",
    "\n",
    "    optim = SGD(model.parameters(), lr=1e-2, momentum=0.6)\n",
    "    loss = nn.MSELoss()\n",
    "    epochs = 10\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        avg_loss = 0\n",
    "        batches = 0\n",
    "        for batch in batched_data:\n",
    "            x,y = batch\n",
    "            optim.zero_grad()\n",
    "            out = model(x)\n",
    "            batch_loss = loss(out,y)\n",
    "            batch_loss.backward()\n",
    "            optim.step()\n",
    "            avg_loss += batch_loss\n",
    "            batches += 1\n",
    "        avg_loss /= batches\n",
    "        print(f\" {epoch+1}/{epochs}: {avg_loss}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a11f0072",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1/10: 0.1483280211687088\n",
      " 2/10: 0.12544582784175873\n",
      " 3/10: 0.11465559899806976\n",
      " 4/10: 0.10929769277572632\n",
      " 5/10: 0.10730025172233582\n",
      " 6/10: 0.10671570152044296\n",
      " 7/10: 0.10510475933551788\n",
      " 8/10: 0.1020856723189354\n",
      " 9/10: 0.10145168751478195\n",
      " 10/10: 0.10060606896877289\n"
     ]
    }
   ],
   "source": [
    "batched_training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae26345e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl_proj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
