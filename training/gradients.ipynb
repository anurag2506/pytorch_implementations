{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward, Loss and Backward Pass\n",
    "\n",
    "- Forward Pass : Where the data moves forward (eg. in a MLP or a CNN) where the activations propogate through the network to produce a prediction\n",
    "                Eg. Y = act(W @ X + b )\n",
    "\n",
    "- Loss : This is the scalar quantity that is calculated from the prediction and the factual data of the observation present. A lower loss is better. \n",
    "                Eg. MSE Loss, BCE loss\n",
    "\n",
    "- Backward: This is where the model learns from previous data rows/batches/whole epochs of data and how much, each of the parameters of the network contributed in the loss.\n",
    "    - We get the gradient of the loss with respect to the parameters of the model using chain rule to check the influence of that parameter on the final loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient (dL/dW)\n",
    "\n",
    "- This is the mathematical derivative of the Loss with respect to a parameter (like W). It tells us the direction and magnitude to change W to reduce the loss.\n",
    "\n",
    "Backward Pass\n",
    "\n",
    "- PyTorch uses Automatic Differentiation (Autograd) to compute all these derivatives efficiently, moving backwards from the scalar loss through the computation graph all the way back to the parameters (W and B).\n",
    "\n",
    "\n",
    "### Updating (Optimizer)\n",
    "\n",
    "- After the backward pass, a component called the Optimizer (not in our script) uses the gradients (W.grad and B.grad) to physically update the parameters: W_new =W_old​ −(Learning Rate×W.grad).\n",
    "\n",
    "\n",
    "### Zeroing Gradients\n",
    "\n",
    "- W.grad = None (or W.grad.zero_()): Gradients accumulate by default. We must zero them out before each new training step so the gradient from the current batch of data is not polluted by the gradient from the previous batch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Methods in PyTorch\n",
    "\n",
    "1. torch.Tensor\n",
    "- The fundamental data structure. It is a multi-dimensional array, similar to a NumPy array, but optimized for GPU computation and gradient tracking.\n",
    "\n",
    "2. `requires_grad=True`\n",
    "- A boolean flag set during tensor creation (e.g., `W = torch.randn(..., requires_grad=True`). This is the signal to PyTorch's Autograd system to track every operation performed on this tensor. Only tensors representing model parameters (W,B) should typically have this set.\n",
    "\n",
    "3. `.grad`\n",
    "- An attribute automatically created and managed by Autograd. After loss.backward() is called, this attribute stores the gradient (∂Loss/∂Parameter) for the tensor. It is initially None.\n",
    "\n",
    "3. `.detach()`\n",
    "- Creates a new tensor that shares the underlying data but detaches the tensor from the current computation graph. Useful when you need the value for logging or visualization without tracking its history.\n",
    "\n",
    "4. `.item()`\n",
    "- Converts a single-element (scalar) PyTorch tensor (like the final loss value) into a standard Python number (float). Essential for printing or logging the loss.\n",
    "\n",
    "5. `.zero_()`\n",
    "- In-place method used on the parameter's .grad attribute (e.g., `optimizer.zero_grad()`). It resets the accumulated gradients to zero before a new backward pass. This is crucial because, by default, PyTorch accumulates gradients across multiple passes.\n",
    "\n",
    "6. `loss.backward()`\n",
    "- The most critical command. It triggers the Autograd engine to traverse the computation graph (which was built during the forward pass) backwards from the scalar loss tensor. It calculates the gradients for all tensors that have requires_grad=True and populates their .grad attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "A = torch.tensor([5.0], requires_grad=True)\n",
    "B = torch.tensor([10.0])\n",
    "C = A * 2\n",
    "D = B * 3\n",
    "E = C + D\n",
    "```\n",
    "\n",
    "Which of the tensors (A, B, C, D, E) will have a computation history tracked by Autograd, and why? If you call E.backward(), which of these tensors will have a non-None value in their .grad attribute, and what does this value physically represent?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.,  0.,  1.])\n"
     ]
    }
   ],
   "source": [
    "# Role of requires_grad:\n",
    "\n",
    "'''\n",
    "The tensors that will have a computation history tracked by Autograd are those derived from a tensor that has requires_grad=True.\n",
    "- By default, requires_grad = False\n",
    "- It has to be explicity specified\n",
    "\n",
    "A,B,E have their history tracked by Autograd. (E as well because If at least one input tensor requires gradients, the output tensor will also require gradients.)\n",
    "B,D dont have their history tracked.\n",
    "'''\n",
    "\n",
    "a = torch.tensor([1,2,3],dtype=torch.float32, requires_grad=True)\n",
    "loss = torch.var(a)\n",
    "loss.backward()\n",
    "print(a.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "W = torch.randn(10, 1, requires_grad=True)\n",
    "X = torch.randn(5, 10)\n",
    "Y_pred = X @ W\n",
    "Y_pred_detached = Y_pred.detach() # Line A\n",
    "loss = torch.sum(Y_pred_detached**2) # Line B\n",
    "\n",
    "If you call loss.backward():\n",
    "\n",
    "Will the gradient ∂Loss/∂W be computed and stored in W.grad? Explain the role of Line A in this context.\n",
    "\n",
    "If you changed Line A to be simply Y_pred_detached = Y_pred, what would change regarding the computation of W.grad?\n",
    "\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.6667,  0.3333,  1.3333]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# Role of .detatch():\n",
    "\n",
    "'''\n",
    "Here Y_pred = X @ W and has history tracked by autograd because its a combination of 2 inputs amongst which one is tracked. \n",
    "But when the .detatch() is called, its gradients are no longer tracked \n",
    "'''\n",
    "\n",
    "a = torch.tensor([[1,3,4]],requires_grad=True,dtype=float)\n",
    "loss = torch.var(a)\n",
    "loss.backward()\n",
    "print(a.grad)\n",
    "# a.detach()\n",
    "# print(a.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.3333, dtype=torch.float64)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mentoroid_conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
