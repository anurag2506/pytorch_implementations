{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a 2D tensor of shape (4, 5) filled with random numbers in [-1, 1] on GPU if available, else CPU. Then: <br>\n",
    "– Print its shape, mean, std, min, max.<br>\n",
    "– Reshape it to (2, 10), then back to (4, 5).<br>\n",
    "– Add a new dimension at axis 1 (so shape becomes (4, 1, 5)), then remove it back.<br>\n",
    "– Move it to float16 if supported, else stay in float32.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: torch.Size([4, 5]), mean:0.2160, std: 0.5982, max: 0.9212484359741211, min: -0.8552501201629639\n",
      "Reshaped tensor: tensor([[-0.0251,  0.9195,  0.1990, -0.1448,  0.8208, -0.3692, -0.2397,  0.6922,\n",
      "         -0.8553,  0.8977],\n",
      "        [ 0.2984,  0.8109, -0.4353,  0.4617,  0.9212, -0.7419,  0.3491,  0.3910,\n",
      "          0.9089, -0.5398]], device='mps:0'), shape : torch.Size([2, 10])\n",
      "Original tensor :tensor([[-0.0251,  0.9195,  0.1990, -0.1448,  0.8208],\n",
      "        [-0.3692, -0.2397,  0.6922, -0.8553,  0.8977],\n",
      "        [ 0.2984,  0.8109, -0.4353,  0.4617,  0.9212],\n",
      "        [-0.7419,  0.3491,  0.3910,  0.9089, -0.5398]], device='mps:0'), shape: torch.Size([4, 5])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "inp = (torch.rand(size=(4,5))*(1+1) - 1).to(device)\n",
    "print(f\"Shape: {inp.shape}, mean:{torch.mean(inp):.4f}, std: {torch.std(inp):.4f}, max: {torch.max(inp)}, min: {torch.min(inp)}\")\n",
    "reshaped = torch.reshape(inp,(2,10))\n",
    "print(f\"Reshaped tensor: {reshaped}, shape : {(reshaped.shape)}\")\n",
    "original = torch.reshape(reshaped,(4,5))\n",
    "print(f\"Original tensor :{original}, shape: {original.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Squeezing and unsqueezing of tensors\n",
    "- manipulating a tensor's shape by adding or removing dimensions with a size of 1\n",
    "- They are essential for ensuring tensors have compatible shapes for operations like broadcasting, matrix multiplication, and feeding data into neural network layers.\n",
    "\n",
    "What they do\n",
    "- torch.unsqueeze(input, dim): This function adds a new dimension with a size of 1 at the specified position (dim).\n",
    "- torch.squeeze(input, dim=None): This function removes all dimensions with a size of 1. If a specific dim is provided, it removes the dimension at that position only if it has a size of 1. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### When is unsqueeze used?\n",
    "- Many neural network layers, such as convolutional layers, expect a 4D tensor with the shape (batch_size, channels, height, width). If you are processing a single image, its shape might be (channels, height, width). You can use unsqueeze(0) to add a batch dimension of size 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = torch.rand((3,228,228)).to(torch.float32)\n",
    "processed_img = torch.unsqueeze(img, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 228, 228])\n",
      "torch.Size([1, 3, 228, 228])\n"
     ]
    }
   ],
   "source": [
    "print(img.shape) # (C,H,W)\n",
    "print(processed_img.shape) # (B,C,H,W)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### When is Squeeze used? \n",
    "\n",
    "- After a computation that results in a dimension of size 1, you might need to remove it to simplify the tensor or match the expected shape for the next operation. For example, a global average pooling layer might produce an output with a dimension of size 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img2 = torch.rand((10,128,1,1))\n",
    "sq_  = torch.squeeze(img2, dim=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sq_ = torch.squeeze(sq_, dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 128])\n",
      "torch.Size([10, 128, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "print(sq_.shape)\n",
    "print(img2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 128, 128, 3])\n",
      "torch.Size([128, 128, 3])\n"
     ]
    }
   ],
   "source": [
    "# Explicit vs Implicit Squeezing\n",
    "input = torch.rand((1,1,128,128,3))\n",
    "input_ = torch.squeeze(input) # Removes all singleton dimensions by default\n",
    "\n",
    "print(input.shape)\n",
    "print(input_.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Your task is to manipulate example_tensor using squeeze and unsqueeze to achieve the target shapes and verify the results. For every step, print the shape of the resulting tensor and the tensor itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# A complex tensor for our exercise\n",
    "data = torch.arange(27).reshape(3, 3, 3).to(torch.float32)\n",
    "example_tensor = data.unsqueeze(0).unsqueeze(2).unsqueeze(-1)\n",
    "print(f\"Initial tensor shape: {example_tensor.shape}\")\n",
    "print(f\"Initial tensor:\\n{example_tensor}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: Universal Squeezing\n",
    "- Remove all dimensions of size 1 from example_tensor without specifying a dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "squeezed_tensor = torch.squeeze(example_tensor) # implicit squeezing\n",
    "print(squeezed_tensor.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2: Selective Squeezing\n",
    "- Start again with the original example_tensor. Squeeze only the batch and channel dimensions (dimensions 0 and 2) in a single operation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "squeezed_new = torch.squeeze(example_tensor,dim = (0,2,5))\n",
    "print(squeezed_new.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3: Sequential Unsqueezing\n",
    "- Start with the torch.Size([3, 3, 3]) tensor you created in Step 1.\n",
    "- Add a batch dimension at the beginning (dim=0).\n",
    "- Add a channel dimension at the end (dim=-1).\n",
    "- Add another dimension of size 1 between the last two dimensions (dim=3). \n",
    "- Expected final shape: torch.Size([1, 3, 3, 1, 3, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 3, 3, 1, 3])\n"
     ]
    }
   ],
   "source": [
    "a = torch.rand((3,3,3,))\n",
    "b = torch.unsqueeze(a,dim=0)\n",
    "# Since the channel dimension must be 3 and the batch dimension must be 1\n",
    "c = torch.unsqueeze(b,-1).expand((1,3,3,3,3))\n",
    "d = torch.unsqueeze(c,-2)\n",
    "print(d.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 4: Unsqueezing for Broadcasting\n",
    "- Consider two tensors:\n",
    "- A = torch.randn(3, 1, 5)\n",
    "- B = torch.randn(5)\n",
    "- Explain why A + B would cause an error. Then, provide the code to unsqueeze B correctly so that the addition is successful, and print the resulting shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Shape of A: torch.Size([3, 1, 5])\n",
      "Shape of B after unsqueezing: torch.Size([1, 1, 5])\n",
      "Resulting shape of C: torch.Size([3, 1, 5])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "A = torch.randn((3, 1, 5))\n",
    "B = torch.randn((5))\n",
    "\n",
    "try:\n",
    "    _ = A + B\n",
    "except RuntimeError as e:\n",
    "    print(f\"Error when adding A and B directly: {e}\")\n",
    "\n",
    "B_unsqueezed = B.unsqueeze(0).unsqueeze(0)\n",
    "print(f\"\\nShape of A: {A.shape}\")\n",
    "print(f\"Shape of B after unsqueezing: {B_unsqueezed.shape}\")\n",
    "\n",
    "# Perform the successful addition\n",
    "C = A + B_unsqueezed\n",
    "print(f\"Resulting shape of C: {C.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 5: Conceptual Question - The View\n",
    "- Start again with the torch.Size([3, 3, 3]) tensor from Step 1 and assign it to a new variable final_tensor.\n",
    "- Perform viewed_tensor = final_tensor.unsqueeze(0).\n",
    "- Perform squeezed_back = viewed_tensor.squeeze(0).\n",
    "- Modify an element in squeezed_back.\n",
    "- Explain whether final_tensor will also be modified, and why. Provide code to demonstrate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = torch.rand((3,3,3))\n",
    "q = p.unsqueeze(0)\n",
    "r = q.squeeze(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "r[0,0,0] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert (p[0,0,0] == r[0,0,0]) # So changing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mentoroid_conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
