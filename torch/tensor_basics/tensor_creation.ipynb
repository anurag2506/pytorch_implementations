{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "96874ab3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensor is tensor([[1, 9, 8, 8, 7],\n",
      "        [0, 5, 5, 4, 6],\n",
      "        [3, 2, 2, 4, 9],\n",
      "        [6, 5, 4, 8, 5]], device='mps:0'), dtype: torch.int64, device:mps:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import math\n",
    "'''\n",
    "Create a tensor from NumPy and check its properties.\n",
    "Create a NumPy array data with shape (4, 5) containing random integers between 0 and 10.\n",
    "Convert this NumPy array to a PyTorch tensor. Print the tensor, its data type (dtype), and its device (device).\n",
    "'''\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "a = np.random.randint(0,10, size=(4,5))\n",
    "b = torch.tensor(a).to(device)\n",
    "print(f\"The tensor is {b}, dtype: {b.dtype}, device:{b.device}\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f7c54e59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dtype of p: torch.int64, q: torch.float32\n",
      "Shape of p: torch.Size([1, 5]), q: torch.Size([3, 3])\n",
      "First 5 elements of p: tensor([ 5,  7,  9, 11, 13])\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Generate a tensor with specific values and examine data types.\n",
    "Use torch.arange to create a tensor with values from 5 to 15 (inclusive) with a step of 2. \n",
    "Use torch.full to create a tensor of shape (3, 3) filled with the value 3.14. \n",
    "Print both tensors and observe their default data types.\n",
    "'''\n",
    "p = torch.arange(start=5,end=15,step=2).reshape(1,5)\n",
    "q = torch.full((3,3),3.14)\n",
    "print(f\"Dtype of p: {p.dtype}, q: {q.dtype}\")\n",
    "print(f\"Shape of p: {p.shape}, q: {q.shape}\")\n",
    "\n",
    "print(f\"First 5 elements of p: {p[0,:5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29ee0ee9",
   "metadata": {},
   "source": [
    "## What are log-spaced values and how can elements be generated, logarithmically spaced between 2 intervals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ffcc356",
   "metadata": {},
   "source": [
    "<i> If N log-spaced values are needed between a and b : </i>\n",
    "\n",
    "$p = (log10​(a))+ i⋅(log10​(b)−log10​(a)​) / (N−1) $ <br>\n",
    "$x_i = 10^p$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4c77185a",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Explore log-spaced values and \"like\" creation.Generate 100 values logarithmically spaced between 1 and 1000.\n",
    "Create a new tensor with the same shape and data type as your log-spaced tensor, but filled with zeros.\n",
    "'''\n",
    "a = []\n",
    "for i in range(100):\n",
    "    exp = math.log(1,10) + (i)*(math.log(1000,10) - math.log(1,10))/(99)\n",
    "    a.append(math.pow(10,exp))\n",
    "a = torch.tensor(a)\n",
    "x = torch.logspace(0,3,100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f2199a8",
   "metadata": {},
   "source": [
    "### Why are Log-spaced values preferred?\n",
    "- Help you in covering same meaningful variations across a huge range as linearly-spaced values\n",
    "        For eg. \n",
    "\n",
    "        $range : [10^-6, 10^3]$ <br>\n",
    "\n",
    "        Number of Linearly spaced points : (10^4-10^6) <br>\n",
    "\n",
    "        Number of Log-spaced values points: (10-20)\n",
    "- Floating-point precision decreases as numbers get very large. Log-spaced sampling ensures coverage across magnitudes while avoiding huge linear steps that “skip” important orders of magnitude.\n",
    "\n",
    "\n",
    "- When the phenomenon is multiplicative, not additive\n",
    "\n",
    "    Many natural & engineered systems scale exponentially (or multiplicatively).\n",
    "\n",
    "    Examples:\n",
    "\n",
    "    1. Learning rates in ML: You don’t test 0.1, 0.2, 0.3… Instead you try 0.0001, 0.001, 0.01, 0.1… → multiplicative changes.\n",
    "\n",
    "    2. Frequency analysis: Human hearing is logarithmic in frequency → octaves, not Hz. So log spacing matches perception.\n",
    "\n",
    "    3. Electronics: Resistors, capacitors often come in logarithmic series (E6, E12 values).\n",
    "\n",
    "    4. Physics: Earthquake magnitudes, sound intensity (decibels), star brightness.\n",
    "\n",
    "    In such cases, equal ratios matter more than equal differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc332ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa192407",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl_proj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
