{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be86b69b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset, TensorDataset, ConcatDataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ee1377",
   "metadata": {},
   "source": [
    "### torch.utils.data\n",
    "Gives building blocks for:\n",
    "- Representing datasets\n",
    "- Wrapping datasets\n",
    "- Loading them in batches, shuffling and multiprocessing\n",
    "- sampling strategies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b642925",
   "metadata": {},
   "source": [
    "Putting it Together (Hierarchy + Differences)\n",
    "\n",
    "- Dataset vs IterableDataset:\n",
    "\n",
    "    Dataset â†’ random access by index.<br>\n",
    "    IterableDataset â†’ stream-like, only __iter__.\n",
    "\n",
    "- Subset, ConcatDataset, ChainDataset:\n",
    "    Wrappers around existing datasets to manipulate them (slice, merge).\n",
    "\n",
    "- Samplers:\n",
    "    Decide the order & probability of sampling indices.\n",
    "    Sequential, Random, WeightedRandom, etc.\n",
    "\n",
    "- BatchSampler:\n",
    "    Groups sampled indices into batches.\n",
    "\n",
    "- DataLoader:\n",
    "    Orchestrates everything: takes dataset (or iterable), sampler, batching, workers, pinning, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3f2f732",
   "metadata": {},
   "source": [
    "Mental Model ðŸ§ \n",
    "\n",
    "Think of it like a data factory pipeline:\n",
    "1. Dataset/IterableDataset = the raw materials.\n",
    "\n",
    "2. Sampler = decides which pieces to pick.\n",
    "\n",
    "3. BatchSampler = packs them into boxes.\n",
    "\n",
    "4. DataLoader = the delivery truck (does multiprocessing, shuffling, etc).\n",
    "\n",
    "5. Wrappers (Subset, ConcatDataset, etc) = tools to rearrange/resize your raw material."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "82424b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Dataset: It defines the interface for all datasets in PyTorch.\n",
    "# Super flexible â†’ you can load anything (images, CSV rows, text files, tensors, API calls, etc).\n",
    "class customDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        self.X = torch.randn((10,3)).to(\"mps\")\n",
    "        self.y = torch.randint(0,2,(10,)).to(\"mps\") # labels: 0,1 \n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    def __getitem__(self, index):\n",
    "        return (self.X[index],self.y[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fd400127",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([ 0.4090,  0.7271, -1.0578], device='mps:0'), tensor(0, device='mps:0'))\n"
     ]
    }
   ],
   "source": [
    "a = customDataset()\n",
    "print(a.__getitem__(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4db67ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. TensorDataset:\n",
    "'''\n",
    "A ready-made implementation of Dataset.\n",
    "Stores tensors of the same length and returns them as tuples.\n",
    "You donâ€™t have to subclass anything. It just pairs tensors sample-by-sample.\n",
    "'''\n",
    "\n",
    "class myDataset():\n",
    "    def __init__(self):\n",
    "        self.X = torch.randn((10,3)).to(\"mps\")\n",
    "        self.y = torch.randint(0,2,(10,)).to(\"mps\")\n",
    "        \n",
    "    def couple_data_labels(self):\n",
    "        data = TensorDataset(self.X,self.y)\n",
    "        return data\n",
    "    \n",
    "    def batch_size(self):\n",
    "        batch_data = self.couple_data_labels()\n",
    "        return batch_data[0].shape\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b95df4e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl_proj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
